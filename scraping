#Web Scraping
#Fake Job Website
#Static Website
#Credits to Real Python's Beautiful Soup: Build a Web Scraper With Python


#Before we start scraping, it's best to explore URL elements with browser's developer tools so that you can inspect html element

#Step 1
#Scrape HTML Content
import requests

URL = 'https://realpython.github.io/fake-jobs/'
page = requests.get(URL)

print(page.text) #showed that the website is static, using html (dynamic web would've been using javascript)

#Step 2
#Parse HTML code with BeautifulSoup
import requests
from bs4 import BeautifulSoup

URL = 'https://realpython.github.io/fake-jobs/'
page = requests.get(URL)

soup = BeautifulSoup(page.content,'html.parser')

results = soup.find(id='ResultsContainer')
results.prettify() #for nicer results

#Look for html elements
job_elements = results.find_all('div', class_='card-content')
for job_element in job_elements:
    title_element = job_element.find('h2', class_='title')
    company_element = job_element.find('h3', class_='company')
    location_element = job_element.find('p', class_='location')
    print(title_element)
    print(company_element)
    print(location_element)
    print()
    
#Extract text from HTML
for job_element in job_elements:
    title_element = job_element.find('h2', class_='title')
    company_element = job_element.find('h3', class_='company')
    location_element = job_element.find('p', class_='location')
    print(title_element.text.strip())
    print(company_element.text.strip())
    print(location_element.text.strip())
    print()
    
    
#Find Class by name & class content
python_jobs = results.find_all('h2', string= lambda text: 'python' in text.lower()) #to filter the specific word in job title
print(python_jobs)
#print(len(python_jobs)) #to find out how many jobs within that filter

#Access Parent element (because we can't just search for text in html objects, will give us None objects)
python_job_elements = [
    h2_element.parent.parent.parent for h2_element in python_jobs] #it turned out that third-level parent of h2 is the way to information needed
    
#to get the link of information needed within the filter ('python)    
for job_element in python_job_elements:
    link_url = job_element.find_all('a')[1]['href']
    print(f'Apply here: {link_url}\n')

